{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "bin6lGwwg8ON",
        "9aWXPH2ohnKE",
        "VOE4e4j4lDl2",
        "_nQyvQXVom01",
        "6_PB3uSqEXT3",
        "k5XiGmS8EXT4",
        "hisdumuEEXT4",
        "beY8EV0xEXT5",
        "oVQXwlGMEXT9",
        "YC3hayCUEXT9",
        "1kvACimjEXUC",
        "UZXpnpucEXUF",
        "7i9DHCigEXUF",
        "FNV1C895EXUF",
        "gDbdsKZpEXUO",
        "Ij7PlKtVEXVA"
      ],
      "authorship_tag": "ABX9TyPtpBKYfxAOloYRrk6jzNtJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAWTTY/khomol/blob/master/ML_Individual_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 1. Mount Drive\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bin6lGwwg8ON"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly we have to mount the drive from google cola.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Also importing the google drive where the file is uploaded and stored."
      ],
      "metadata": {
        "id": "fRFpiYKFhz5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZ21hIJFDKy6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Path MyDrive"
      ],
      "metadata": {
        "id": "9aWXPH2ohnKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can instruct IPython to change its own working directory by typing cd or%cd.\n",
        " \n",
        "This will continue during your IPython session, but it will not change the shell from which you started IPython. \n",
        "\n",
        "That shell will still be in the directory it was in when you began IPython after you end IPython."
      ],
      "metadata": {
        "id": "wT3rIHQsjv_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/gdrive/MyDrive/'"
      ],
      "metadata": {
        "id": "JSa53FPRNBWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Pip Installation \n"
      ],
      "metadata": {
        "id": "VOE4e4j4lDl2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lwAaZ8pYxhem"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "!pip installation of command that will perform most basic functions i.e the installation of particular analysis tools\n",
        "\n",
        "Through useful visuals, missingno offers the ability to comprehend the distribution of missing values. \n",
        "\n",
        "Others are panda filing, empiricaldist which disturb the empirical function and factor analyzer to analyze exploratory and factor analysis (EFA)"
      ],
      "metadata": {
        "id": "hs9GIlMhxhnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install missingno\n",
        "!pip install pandas-profiling\n",
        "!pip install empiricaldist\n",
        "!pip install factor-analyzer"
      ],
      "metadata": {
        "id": "36IMUerTNQjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Loading analysis tools\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_nQyvQXVom01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading required analysis tools which i.e panda, nump, mateplotlib,seaborn which are the specified tools for the operation."
      ],
      "metadata": {
        "id": "a5evpDgXxpQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import missingno as msno\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.max_columns', 100)"
      ],
      "metadata": {
        "id": "o4VKhdXCOUxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Loading data "
      ],
      "metadata": {
        "id": "6xg08MGfuzn0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading data which are the train and test files that are uploaded to colab drive or Mydrive\n",
        "\n",
        "*   here we can fetch the dataset and also read the information of individual listed on file\n",
        "*   This files are sorted using panda to call up the csv files\n",
        "\n"
      ],
      "metadata": {
        "id": "xMMTIxsszJT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "QhFIvWEsSF0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recognisation of first dataset"
      ],
      "metadata": {
        "id": "pS86xEbeyINY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YRK-mdRNy5yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "id": "JAIxnRQcSgdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.tail()"
      ],
      "metadata": {
        "id": "H_GdqOvESlbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "Yj0wueX5SuRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train dataset (rows, cols):\",train.shape, \"\\nTest dataset (rows, cols):\",test.shape)"
      ],
      "metadata": {
        "id": "UBZf8AbXTObs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_profiling as pdp"
      ],
      "metadata": {
        "id": "uZIPUjAxTYHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z40Fi9nxvUyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Additional format\n",
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import tqdm\n",
        "from typing import Dict\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install chart_studio\n",
        "import plotly.express as px\n",
        "import chart_studio.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "from plotly.offline import iplot\n",
        "import cufflinks\n",
        "cufflinks.go_offline()\n",
        "cufflinks.set_config_file(world_readable=True, theme='pearl')"
      ],
      "metadata": {
        "id": "n6e9xFI4UNqF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "id": "WitIdfz7dNkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yU7DDMqOvz24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for feature in train.columns:\n",
        "    # Defining the role\n",
        "    if feature == 'target':\n",
        "        role = 'target'\n",
        "    elif feature == 'id':\n",
        "        role = 'id'\n",
        "    else:\n",
        "        role = 'input'\n",
        "         \n",
        "    # Defining the level\n",
        "    if 'bin' in feature or feature == 'target':\n",
        "        level = 'binary'\n",
        "    elif 'cat' in feature or feature == 'id':\n",
        "        level = 'nominal'\n",
        "    elif train[feature].dtype == float:\n",
        "        level = 'interval'\n",
        "    else:\n",
        "        level = 'ordinal'\n",
        "        \n",
        "    # Initialize keep to True for all variables except for id\n",
        "    keep = True\n",
        "    if feature == 'id':\n",
        "        keep = False\n",
        "    \n",
        "    # Defining the data type \n",
        "    dtype = train[feature].dtype\n",
        "    \n",
        "    # Creating a Dict that contains all the metadata for the variable\n",
        "    feature_dict = {\n",
        "        'varname': feature,\n",
        "        'role': role,\n",
        "        'level': level,\n",
        "        'keep': keep,\n",
        "        'dtype': dtype\n",
        "    }\n",
        "    data.append(feature_dict)\n",
        "    \n",
        "meta1 = pd.DataFrame(data, columns=['varname', 'role', 'level', 'keep', 'dtype'])\n",
        "meta1.set_index('varname', inplace=True)\n",
        "meta1"
      ],
      "metadata": {
        "id": "PMB0ruBVdWQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9QL4vInetqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Sc3-yWaEXTz"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "for feature in train.columns:\n",
        "    # Defining the role\n",
        "    if feature == 'target':\n",
        "        use = 'target'\n",
        "    elif feature == 'id':\n",
        "        use = 'id'\n",
        "    else:\n",
        "        use = 'input'\n",
        "         \n",
        "    # Defining the type\n",
        "    if 'bin' in feature or feature == 'target':\n",
        "        type = 'binary'\n",
        "    elif 'cat' in feature or feature == 'id':\n",
        "        type = 'categorical'\n",
        "    elif train[feature].dtype == float or isinstance(train[feature].dtype, float):\n",
        "        type = 'real'\n",
        "    else:\n",
        "        type = 'integer'\n",
        "        \n",
        "    # Initialize preserve to True for all variables except for id\n",
        "    preserve = True\n",
        "    if feature == 'id':\n",
        "        preserve = False\n",
        "    \n",
        "    # Defining the data type \n",
        "    dtype = train[feature].dtype\n",
        "    \n",
        "    category = 'none'\n",
        "    # Defining the category\n",
        "    if 'ind' in feature:\n",
        "        category = 'individual'\n",
        "    elif 'reg' in feature:\n",
        "        category = 'registration'\n",
        "    elif 'car' in feature:\n",
        "        category = 'car'\n",
        "    elif 'calc' in feature:\n",
        "        category = 'calculated'\n",
        "    \n",
        "    \n",
        "    # Creating a Dict that contains all the metadata for the variable\n",
        "    feature_dictionary = {\n",
        "        'varname': feature,\n",
        "        'use': use,\n",
        "        'type': type,\n",
        "        'preserve': preserve,\n",
        "        'dtype': dtype,\n",
        "        'category' : category\n",
        "    }\n",
        "    data.append(feature_dictionary)\n",
        "    \n",
        "meta2 = pd.DataFrame(data, columns=['varname', 'use', 'type', 'preserve', 'dtype', 'category'])\n",
        "meta2.set_index('varname', inplace=True)\n",
        "meta2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc400033-7d77-4456-8913-f4de5c74a99c",
        "_uuid": "21b7012bf25c31060a7e7b9a1139246d1edfeec5",
        "id": "1_sSrDx1EXT1"
      },
      "outputs": [],
      "source": [
        "meta2[(meta2.type == 'categorical') & (meta2.preserve)].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ec2dd532-5d60-472a-9816-02bb02a79bdb",
        "_uuid": "4a52ea8b5a9df61368ac239e1953e3d23e6e722a",
        "id": "gsJzp_c_EXT2"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'count' : meta2.groupby(['category'])['category'].size()}).reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9pXauABi00NH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRmUYkd-EXT3"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({'count' : meta2.groupby(['use', 'type'])['use'].size()}).reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_PB3uSqEXT3"
      },
      "source": [
        "# Exploratory Data Analysis (EDA) <a name='eda'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5XiGmS8EXT4"
      },
      "source": [
        "## Data Quality Issues <a name='data_quality'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hisdumuEEXT4"
      },
      "source": [
        "### Data duplications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNjhmvrCEXT4"
      },
      "outputs": [],
      "source": [
        "train.drop_duplicates()\n",
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Ujvd5BEXT5"
      },
      "outputs": [],
      "source": [
        "test.drop_duplicates()\n",
        "test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deOILwffEXT5"
      },
      "source": [
        "Observations:\n",
        "* **Train** has 595,212 rows and 59 variables\n",
        "* 1 one missing variable in the **Test** (58 variables) \n",
        "* no duplication in both **Train** and **Test** dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beY8EV0xEXT5"
      },
      "source": [
        "### Missing Values\n",
        "Missing values represented by -1 can be replaced with NaN. Most of the classifiers have pretty good strategies to manage missing (or NaN) values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RV8as2n6EXT6"
      },
      "outputs": [],
      "source": [
        "def _impute_missing_data(data):\n",
        "    return data.replace(-1, np.nan)\n",
        "\n",
        "train = _impute_missing_data(train)\n",
        "test = _impute_missing_data(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1ck_kpYEXT6"
      },
      "outputs": [],
      "source": [
        "print('NaN values =', train.isnull().sum().sum())\n",
        "print(\"\"\"\"\"\")\n",
        "\n",
        "vars_with_missing = []\n",
        "\n",
        "for feature in train.columns:\n",
        "    missings = train[feature].isna().sum()\n",
        "    \n",
        "    if missings > 0 :\n",
        "        vars_with_missing.append(feature)\n",
        "        missings_perc = missings / train.shape[0]\n",
        "        \n",
        "        print('Variable {} has {} records ({:.2%}) with missing values.'.format(feature, missings, missings_perc))\n",
        "print('In total, there are {} variables with missing values'.format(len(vars_with_missing)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmrQlwHwEXT7"
      },
      "source": [
        "We can use **missingno** package to visualise the missing values. To do that, we must first replace the -1 values into NAN value, then use  missingno.\n",
        "Note: if missingno has not been previously installed, you can install it using the following command within Jupyter-notebook: \n",
        "**!pip install missingno**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McyL6FawEXT7"
      },
      "outputs": [],
      "source": [
        "import missingno as msno  # Visualize missing values\n",
        "%matplotlib inline\n",
        "msno.matrix(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WEa9L3JEXT7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "msno.bar(train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NRKq5bvEXT8"
      },
      "source": [
        "Observations:\n",
        "- **ps_car_03_cat and ps_car_05_cat** have a large proportion of  records with missing values. Remove these variables.\n",
        "- For the other categorical variables with missing values, we can leave the missing value -1 as such.\n",
        "- **ps_reg_03** (real/interval) has missing values for 18% of all records. Replace by the mean.\n",
        "- **ps_car_11** (categorical/ordinal) has only 5 records with misisng values. Replace by the mode.\n",
        "- **ps_car_12** (real/interval) has only 1 records with missing value. Replace by the mean.\n",
        "- **ps_car_14** (real/interval) has missing values for 7% of all records. Replace by the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQ0FhvvhEXT8"
      },
      "outputs": [],
      "source": [
        "msno.heatmap(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FALRgUDEXT8"
      },
      "source": [
        "Observations:\n",
        "- **ps_ind_01_cat/ps_ind_02_cat/ps_ind_04_cat** have the same missing values \n",
        "- missing value relationship between **ps_car_03_cat/ps_ind_02_cat** seems very similar to **ps_car_03_cat/ps_ind_04_cat**\n",
        "- missing value relationship between **ps_car_07_cat/ps_ind_02_cat** seems very similar to **ps_car_07_cat/ps_ind_04_cat** and **ps_car_07_cat/ps_car_01_cat and ps_ind_05_cat/ps_ind_02_cat** and **ps_ind_05_cat/ps_ind_04_cat** \n",
        "- Negative relationships may suggest imputational opportunities are they signify cases where missing values exist in one variable but not in another "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0C8_abdEXT8"
      },
      "outputs": [],
      "source": [
        "df_missing_train = pd.DataFrame({'column':train.columns, 'missing(%)':((train.isna()).sum()/train.shape[0])*100})\n",
        "df_missing_test = pd.DataFrame({'column':train.columns, 'missing(%)':((train.isna()).sum()/train.shape[0])*100})\n",
        "\n",
        "df_missing_train_nl = df_missing_train.nlargest(7, 'missing(%)')\n",
        "df_missing_test_nl = df_missing_test.nlargest(7, 'missing(%)')\n",
        "\n",
        "sns.set_palette(sns.color_palette('nipy_spectral'))\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.barplot(data= df_missing_train_nl, x='column', y='missing(%)',palette='nipy_spectral')\n",
        "plt.title('Missing values (%) in training set')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.barplot(data= df_missing_test_nl, x='column', y='missing(%)',palette='nipy_spectral')\n",
        "plt.title('Missing values (%) in test set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0GMTc52EXT9"
      },
      "source": [
        "Observations: Missing value proportions tend to be consistent across the **train** and **test** dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVQXwlGMEXT9"
      },
      "source": [
        "## Univariate Exploration <a name='univariate_exploration'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC3hayCUEXT9"
      },
      "source": [
        "### Binary features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iaPmIjMEXT9"
      },
      "source": [
        "Let's plot the histogram of **target** column within the **train** dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPxTuHg1EXT-"
      },
      "outputs": [],
      "source": [
        "sns.set_style('white')\n",
        "sns.set(font_scale=1)\n",
        "plt.figure()\n",
        "sns.countplot(x=train['target'],palette='nipy_spectral')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFGY6IXbEXT-"
      },
      "source": [
        " Let's obtain get the descriptive the binary features within the  **train** dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8--DihqlEXT_"
      },
      "outputs": [],
      "source": [
        "v = meta2[(meta2.type == 'binary') & (meta2.preserve)].index\n",
        "train[v].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjW2D69UEXT_"
      },
      "source": [
        "Observations:\n",
        "\n",
        "- The mean value of **target** in the **train** dataset is 3.6448%, which is **strongly imbalanced** between zeros and ones.\n",
        "- From the means we can conclude that for most variables the value is zero in most cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnpuqJBsEXT_"
      },
      "source": [
        "Let's plot the distribution of the binary data in the **train** dataset,  with **blue** represent the percent of 0, and the **red** represent the percent of 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTK1yYReEXUA"
      },
      "outputs": [],
      "source": [
        "bin_col = [col for col in train.columns if '_bin' in col]\n",
        "zero_list = []\n",
        "one_list = []\n",
        "for col in bin_col:\n",
        "    zero_list.append((train[col]==0).sum()/train.shape[0]*100)\n",
        "    one_list.append((train[col]==1).sum()/train.shape[0]*100)\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(figsize=(6,6))\n",
        "# Bar plot\n",
        "p1 = sns.barplot(ax=ax, x=bin_col, y=zero_list, color=\"blue\")\n",
        "p2 = sns.barplot(ax=ax, x=bin_col, y=one_list, bottom= zero_list, color=\"red\")\n",
        "plt.ylabel('Percent of zero/one [%]', fontsize=12)\n",
        "plt.xlabel('Binary features', fontsize=12)\n",
        "locs, labels = plt.xticks()\n",
        "plt.setp(labels, rotation=90)\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PufqehFcEXUA"
      },
      "source": [
        "Observations: **ps_ind_10_bin**, **ps_ind_11_bin**, **ps_ind_12_bin** and **ps_ind_13_bin** have very small number of values 1 (lesss than 0.5%) whilst the number of value 1 is very large for **ps_ind_16_bin** and **ps_cals_16_bin** (more than 60%).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvO0a2OEEXUB"
      },
      "source": [
        "Let's see the distribution of **binary** variables and the corresponding values of **target** variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJTKB3myEXUC"
      },
      "outputs": [],
      "source": [
        "var = meta2[(meta2.type == 'binary') & (meta2.preserve)].index\n",
        "var = [col for col in train.columns if '_bin' in col]\n",
        "i = 0\n",
        "t1 = train.loc[train['target'] != 0]\n",
        "t0 = train.loc[train['target'] == 0]\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(5,4,figsize=(16,16))\n",
        "\n",
        "for feature in var:\n",
        "    i += 1\n",
        "    plt.subplot(5,4,i)\n",
        "    sns.kdeplot(t1[feature], bw_adjust=20)\n",
        "    sns.kdeplot(t0[feature], bw_adjust=20)\n",
        "    plt.ylabel('Density plot', fontsize=12)\n",
        "    plt.xlabel(feature, fontsize=12)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "    plt.legend(['targe=1', 'target=0'], loc='best')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kvACimjEXUC"
      },
      "source": [
        "### Categorical (Nominal) features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPrYSMN1EXUD"
      },
      "source": [
        "Let's see the distribution of **categorical** variables and the corresponding values of **target** variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2AHCMLSEXUD"
      },
      "outputs": [],
      "source": [
        "var = meta2[(meta2.type == 'categorical') & (meta2.preserve)].index\n",
        "i = 0\n",
        "t1 = train.loc[train['target'] != 0]\n",
        "t0 = train.loc[train['target'] == 0]\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "plt.figure()\n",
        "fig, ax = plt.subplots(4,4,figsize=(16,16))\n",
        "\n",
        "for feature in var:\n",
        "    i += 1\n",
        "    plt.subplot(4,4,i)\n",
        "    sns.kdeplot(t1[feature], bw_adjust=20)\n",
        "    sns.kdeplot(t0[feature], bw_adjust=20)\n",
        "    plt.ylabel('Density plot', fontsize=12)\n",
        "    plt.xlabel(feature, fontsize=12)\n",
        "    locs, labels = plt.xticks()\n",
        "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "    plt.legend(['targe=1', 'target=0'], loc='best')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiawgwppEXUD"
      },
      "source": [
        "We calculate the percentage of target=1 per category value and represent these percentages using bar plots (histogram)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfHA4yiIEXUE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "var = meta2[(meta2.type == 'categorical') & (meta2.preserve)].index\n",
        "\n",
        "for feature in var:\n",
        "    fig, ax = plt.subplots(figsize=(6,6))\n",
        "    # Calculate the percentage of target=1 per category value\n",
        "    cat_perc = train[[feature, 'target']].groupby([feature],as_index=False).mean()\n",
        "    cat_perc.sort_values(by='target', ascending=False, inplace=True)\n",
        "    # Bar plot\n",
        "    # Order the bars descending on target mean\n",
        "    sns.barplot(ax=ax,x=feature, y='target', data=cat_perc, order=cat_perc[feature])\n",
        "    plt.ylabel('Percent of target with value 1 [%]', fontsize=12)\n",
        "    plt.xlabel(feature, fontsize=12)\n",
        "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "    plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYr7FU-rEXUE"
      },
      "source": [
        "Here, we check the cardinality of the categorical variables. Cardinality refers to the number of different values in a variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i24QX9gMEXUE"
      },
      "outputs": [],
      "source": [
        "var = meta2[(meta2.type == 'categorical') & (meta2.preserve)].index\n",
        "\n",
        "for feature in var:\n",
        "    dist_values = train[feature].value_counts().shape[0]\n",
        "    print('Variable {} has {} distinct values'.format(feature, dist_values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4yVUyLoEXUE"
      },
      "source": [
        "Observations: Only **ps_car_11_cat** has many distinct values, although it is still reasonable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZXpnpucEXUF"
      },
      "source": [
        "### Real (Interval) features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2UdatD-EXUF"
      },
      "outputs": [],
      "source": [
        "variable = meta2[(meta2.type == 'real') & (meta2.preserve)].index\n",
        "train[variable].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZk9rzlbEXUF"
      },
      "source": [
        "Observation:\n",
        "\n",
        "**reg**: The range (min to max) differs between the variables. We could apply scaling (e.g. StandardScaler), but it depends on the classifier we will want to use\n",
        "\n",
        "**car**: Again, the range differs and we could apply scaling\n",
        "\n",
        "**calc**: This seems to be some kind of ratio as the maximum is 0.9. All three *_calc* variables have very similar distributions\n",
        "\n",
        "**Overall**, we can see that the range of the interval variables is rather small. Perhaps some transformation (e.g. log) is already applied in order to anonymise the data?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i9DHCigEXUF"
      },
      "source": [
        "## Bivariate Exploration <a name='bivariate_exploration'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNV1C895EXUF"
      },
      "source": [
        "### Real (Interval) features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCHGwebpEXUF"
      },
      "source": [
        "Let's visualise the relationship between features in the Real (Interval) variables using Correlation \n",
        "Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiZkAvviEXUG"
      },
      "outputs": [],
      "source": [
        "def corr_heatmap(sample, masking=False):\n",
        "    sns.set_style('whitegrid')\n",
        "    # Create color map ranging between two colors\n",
        "    cmap = sns.diverging_palette(50, 10, as_cmap=True)\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    \n",
        "    if masking==False:\n",
        "        correlations = sample.corr()\n",
        "        sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f', \n",
        "                    square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .75})\n",
        "    else:\n",
        "        correlations = np.triu(sample.corr())\n",
        "        sns.heatmap(sample.corr(), cmap=cmap, vmax=1.0, center=0, fmt='.2f',\n",
        "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .75}, \n",
        "                    mask=correlations)\n",
        "    plt.show();    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9hZLpchEXUG",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "sample = train.sample(1000)\n",
        "var = meta2[(meta2.type == 'real') & (meta2.preserve)].index\n",
        "sample = sample[var]\n",
        "corr_heatmap(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGlgIG2BEXUG"
      },
      "source": [
        "Observations - The variables with strong correlations are:\n",
        "- ps_reg_02 and ps_reg_03\n",
        "- ps_car_12 and ps_car13\n",
        "- ps_car_12 and ps_car14\n",
        "- ps_car_13 and ps_car15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlxymwkcEXUH"
      },
      "outputs": [],
      "source": [
        "corr_heatmap(sample, masking=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltz8sQ1yEXUH"
      },
      "source": [
        "Let's visualise the features with strong correlations in the Real (Interval) variables using Pairplot "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKFMxN8LEXUI"
      },
      "outputs": [],
      "source": [
        "sample = train.sample(1000)\n",
        "var = ['ps_reg_01', 'ps_reg_02', \n",
        "       'ps_reg_03', 'ps_car_12', \n",
        "       'ps_car_13', 'ps_car_14',\n",
        "       'ps_car_15', 'target']\n",
        "sample = sample[var]\n",
        "sns.pairplot(sample,  hue='target', \n",
        "             palette = 'Set1', diag_kind='kde')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j267DDsIEXUI"
      },
      "source": [
        "Let's visualise the correlation between 2 specific features in the Real (Interval) variables using linear model plot (lmplot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXRQWSg7EXUI"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='ps_reg_02', y='ps_reg_03', data=sample, \n",
        "           hue='target', palette='Set1', \n",
        "           scatter_kws={'alpha':0.3})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVwKbCU1EXUJ"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='ps_car_15', y='ps_car_13', data=sample, \n",
        "           hue='target', palette='Set1', \n",
        "           scatter_kws={'alpha':0.3})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFTTirokEXUJ"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='ps_car_12', y='ps_car_13', data=sample, \n",
        "           hue='target', palette='Set1', \n",
        "           scatter_kws={'alpha':0.3})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVbL--KsEXUJ"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='ps_car_12', y='ps_car_14', data=sample, \n",
        "           hue='target', palette='Set1', \n",
        "           scatter_kws={'alpha':0.3})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzqXOEfvEXUK"
      },
      "source": [
        "Let's visualise the correlation between 2 specific features in the Real (Interval) variables using Joint-Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX2pbD79EXUK"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='ps_reg_02', y='ps_reg_03', data=sample, \n",
        "              kind=\"hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1hMAoOaEXUL"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='ps_car_15', y='ps_car_13', data=sample, \n",
        "              kind=\"hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re11LAw1EXUL"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='ps_car_12', y='ps_car_13', data=sample, \n",
        "              kind=\"hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SviuQGSZEXUM"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='ps_car_12', y='ps_car_14', data=sample, \n",
        "              kind=\"hist\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3Q1K0J4EXUN"
      },
      "outputs": [],
      "source": [
        "sample_nc = train.sample(1000)\n",
        "var_nc = ['ps_calc_01', 'ps_calc_02', 'ps_calc_03', 'target']\n",
        "sample_nc = sample_nc[var_nc]\n",
        "\n",
        "sns.lmplot(x='ps_calc_01', y='ps_calc_02', data=sample_nc, \n",
        "           hue='target', palette='Set1', scatter_kws={'alpha':0.3})\n",
        "sns.lmplot(x='ps_calc_01', y='ps_calc_03', data=sample_nc, \n",
        "           hue='target', palette='Set1', scatter_kws={'alpha':0.3})\n",
        "\n",
        "sns.jointplot(x='ps_calc_01', y='ps_calc_02', data=sample_nc, kind=\"hist\")\n",
        "sns.jointplot(x='ps_calc_02', y='ps_calc_03', data=sample_nc, kind=\"hist\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QytP22ipEXUO"
      },
      "source": [
        "Question: How can we decide which of the correlated variables to keep?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDbdsKZpEXUO"
      },
      "source": [
        "### Integer (Ordinal) features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npnkM0DdEXUP"
      },
      "source": [
        "Let's visualise the relationship between features in the Integer (Ordinal) variables using Correlation Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqoFB-4VEXUP"
      },
      "outputs": [],
      "source": [
        "sample = train.sample(1000)\n",
        "var = meta2[(meta2.type == 'integer') & (meta2.preserve)].index\n",
        "sample = sample[var]\n",
        "corr_heatmap(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r_IGQu0EXUQ"
      },
      "source": [
        "Observations: For the *integer* variables we do not see many correlations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGa7zDe1EXUQ"
      },
      "outputs": [],
      "source": [
        "def corr_heatmap1(sample, method):\n",
        "    sns.set_style('whitegrid')\n",
        "    # Create color map ranging between two colors\n",
        "    cmap = sns.diverging_palette(50, 10, as_cmap=True)\n",
        "    fig, ax = plt.subplots(figsize=(10,10))\n",
        "    correlations = sample.corr(method)\n",
        "    sns.heatmap(correlations, cmap=cmap, vmax=1.0, center=0, fmt='.2f', \n",
        "                square=True, linewidths=.5, annot=True, cbar_kws={\"shrink\": .75})\n",
        "    plt.show();    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4I6yekPEXUQ"
      },
      "outputs": [],
      "source": [
        "corr_heatmap1(sample, 'kendall')\n",
        "corr_heatmap1(sample, 'spearman')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5YDxR4JEXUR"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='ps_ind_01', y='ps_ind_03', data=sample, kind=\"hist\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bULnRiTIEXUR"
      },
      "outputs": [],
      "source": [
        "sns.jointplot(x='ps_ind_01', y='ps_calc_04', data=sample, kind=\"hist\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k499PgvDEXUS"
      },
      "source": [
        "Let's visualise the probabilities of the possible values for a variable using Probability Mass Function (PMF). PMF requires empiricaldist package. If not available, you may tnstall empiricaldist using the following command line: <br>\n",
        "!pip install empiricaldist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7B8O0pJqEXUS"
      },
      "outputs": [],
      "source": [
        "from empiricaldist import Cdf, Pmf\n",
        "train_pmf = train.sample(n = 500)\n",
        "fig, ax = plt.subplots()\n",
        "# Extract the unique categories\n",
        "categories = train_pmf['ps_ind_02_cat'].unique()\n",
        "for cat in categories:\n",
        "    pmf_cat = Pmf.from_seq(train_pmf[\n",
        "        train_pmf['ps_ind_02_cat'] == cat]['ps_car_12'])\n",
        "    ax.plot(pmf_cat, label=cat)\n",
        "ax.set(xlabel='ps_car_12',\n",
        "       ylabel='P(X = x)')\n",
        "plt.title('The number of categories: {}'.format(len(categories)))\n",
        "ax.legend()\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_z58c2aEXUS"
      },
      "source": [
        "Let's visualise the distribution between 2 specific features The ‘boxenplot’ is a nonparametric representation of a distribution in which all features correspond to actual observations. By plotting more quantiles, it provides more information about the shape of the distribution, particularly in the tails. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAWZ53AvEXUW"
      },
      "outputs": [],
      "source": [
        "sns.boxenplot(x=train_pmf.ps_car_14.astype('float'), \n",
        "              y=train_pmf.ps_car_10_cat.astype('category'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxu6Kk8eEXUW"
      },
      "outputs": [],
      "source": [
        "train_clustermap = train.sample(n = 50)\n",
        "int_features = train_clustermap.select_dtypes(include=['int64']).columns.tolist()\n",
        "ordinal_features = [o for o in int_features if \n",
        "                    ('cat' not in o and 'bin' not in o and 'id' not in o and 'target' not in o )]\n",
        "ord_features_df = train_clustermap[ordinal_features]\n",
        "sns.clustermap(ord_features_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "de7a1f63-ccb4-49f0-bf3e-8e1181c5c5be",
        "_uuid": "b8aa7aee1c138ab00cecc0197b33d07d9a1cc1e0",
        "id": "Ij7PlKtVEXVA"
      },
      "source": [
        "## Conclusion\n",
        "I hope  this notebook helped you learn the exploratory data analysis (EDA) workflow, that is an important initial steps before proceeding to the data preprocessing for the ML model development."
      ]
    }
  ]
}